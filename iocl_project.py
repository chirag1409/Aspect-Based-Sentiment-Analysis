# -*- coding: utf-8 -*-
"""Copy of iocl_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1O6fQUs0HPvx1KW_I3PMyDCQaRtZWqHpA

### **IOCL**

**Data Loading**
"""



from google.colab import drive
drive.mount('/content/drive')

#! mkdir ~/.kaggle

#! cp kaggle.json ~/.kaggle/

#! chmod 600 ~/.kaggle/kaggle.json

#!kaggle datasets download aashita/nyt-comments -f CommentsApril2017.csv -p /content/

#from zipfile import ZipFile
#with ZipFile("CommentsApril2017.csv.zip", 'r') as zip:
#  zip.extractall()

import pandas as pd
from collections import Counter
data = pd.read_csv("/content/drive/MyDrive/IOCreviews5000.csv")

data.shape

def f(s):
  if s=="Haryana" :
    return 1
  elif s=="Madhya Pradesh" :
    return 2
  elif s=="Manipur" :
    return 3
  elif s=="Telangana" :
    return 4
  elif s=="Bihar" :
    return 5
  elif s=="Assam" :
    return 6
  elif s=="Punjab" :
    return 7
  else :
    return 8

data["State"] = data.state.apply(f)

data.shape

!pip install pandasql
from pandasql import sqldf
q1 = """
         select 'RO Code', 'PIN Code','State', 'Rating', 'Review'

"""

data.shape

#pysqldf = lambda q: sqldf(q, globals())
#data = pysqldf(q1)

data.shape

## Counter(clean["editorsSelection"])

"""** *Text Cleaning**

> Indented block


"""

!pip install nltk
import nltk
nltk.download("all")
from nltk import sent_tokenize

sentences = [] # each comment as a doc
for i in data["Review"]:
    s=sent_tokenize(i)
    sentences.append(s)
sentences[0]



# tokenization
from nltk.tokenize import word_tokenize
token_list= []
for i in sentences: # i is comment level
    for j in i:
      tokens = word_tokenize(j)
      words = [word for word in tokens if word.isalpha()]
      words = [word.lower() for word in words]
      token_list.append(words)

# lemmatization
from nltk.stem import WordNetLemmatizer
from nltk.corpus import wordnet
lemmatizer = WordNetLemmatizer()
def pos_tagger(nltk_tag):
    if nltk_tag.startswith('J'):
        return wordnet.ADJ
    elif nltk_tag.startswith('V'):
        return wordnet.VERB
    elif nltk_tag.startswith('N'):
        return wordnet.NOUN
    elif nltk_tag.startswith('R'):
        return wordnet.ADV
    else:
        return None
lemma_list = []
for i in token_list:
  pos_tagged = nltk.pos_tag(i)
  wordnet_tagged = list(map(lambda x: (x[0], pos_tagger(x[1])), pos_tagged))
  lemma = []
  for word, tag in wordnet_tagged:
    if word == "i":
      continue
    if tag is None:
      # if there is no available tag, append the token as is
      lemma.append(word)
    else:
      # else use the tag to lemmatize the token
      lemma.append(lemmatizer.lemmatize(word, tag))
  lemma_list.append(lemma)

"""**Aspect Extraction**"""

bi = []
for item in lemma_list:
  grams = [item[i:i+2] for i in range(len(item)-2+1)]
  bigrams = [' '.join(j) for j in grams]
  bi.append(bigrams)

bi_v = [bigram for i in bi for bigram in i]
uni_v = [unigram for i in lemma_list for unigram in i]

counter_bi = Counter(bi_v)

from nltk.corpus import stopwords

# filter before computing for less noise
for i in list(counter_bi.keys()):
  if i.split()[0] in stopwords.words('english'):
    if i.split()[1] in stopwords.words('english'):
      counter_bi.pop(i)

for i in list(counter_bi.keys()):
  w,t = nltk.pos_tag(i.split())[0]
  w1,t1 = nltk.pos_tag(i.split())[1]
  if t[0] != "N":
    if t1[0] != "N":
      counter_bi.pop(i)

import math
def pmi_index(bigram):
  a, b = bigram.split()
  new = []
  for i in bi_v:
    if i != bigram:
      for wor in i.split():
        new.append(wor)
    else:
      new.append(i)
  counter_new = Counter(new)
  if counter_new[a] == 0 or counter_new[b] == 0:
    pmi = "dependent"
  else:
    pmi = math.log(counter_new[bigram]/((counter_new[a]-counter_new[bigram])*(counter_new[b]-counter_new[bigram])/(len(new)-2*counter_new[bigram])))
  return pmi

counter_b = counter_bi.most_common(100)

bi_gram_list = [k for (k,v) in counter_b]

frequency = [v for (k,v) in counter_b]

from cmath import sqrt

pmi = [pmi_index(k) for (k,v) in counter_b]

fre_df = pd.DataFrame({"bigram":bi_gram_list, "pmi":pmi, "frequency": frequency})

fre_most = fre_df.sort_values(by="pmi", ascending=False).head(50)
fre_most

select = fre_most.drop([60,51,0,43])
select_bi = select["bigram"] # bigrams selected

len(select_bi)

from collections import defaultdict
bi_dict = defaultdict(list)
for bi in select_bi:
  f,s = bi.split()
  bi_dict[f].append(s)

sent_c = []
for sent in lemma_list:
  if len(sent) > 1:
    sent_list = []
    for i in range(len(sent)-1):
      if sent[i] in list(bi_dict.keys()):
        if sent[i+1] in bi_dict[sent[i]]:
          bi = sent[i] + " " + sent[i+1]
          sent_list.append(bi)
        else:
          if sent[i] not in stopwords.words('english'):
            sent_list.append(sent[i])
      else:
        if sent[i] not in stopwords.words('english'):
          sent_list.append(sent[i])
    sent_c.append(sent_list)
  elif len(sent) == 1:
    if sent[0] not in stopwords.words('english'):
      sent_c.append(sent)
    else:
      sent_c.append([])
  else:
    sent_c.append([])

sent1 = [] # comment level
for c in sentences:
  ll = []
  for s in c:
    tokens = word_tokenize(s)
    words = [word for word in tokens if word.isalpha()]
    words = [word.lower() for word in words]
    words = [word for word in words if word != 'i']
    ll.append(words)
  sent1.append(ll)

num_com = len(sentences)

com_sent = [] # basic list is sentence
count = 0
for i in range(num_com):
  end = count + len(sent1[i])
  cc = sent_c[count:end]
  com_sent.append(cc)
  count = end

comment = [] # basic list is comment
for com in com_sent:
  c = []
  for sent in com:
    for wor in sent:
      c.append(wor)
  comment.append(c)

noun = []
for com in comment:
  c = []
  for wor in com:
    if wor in select_bi:
      c.append(wor)
    else:
      w, t = nltk.pos_tag([wor])[0]
      if t[0] == "N":
        c.append(wor)
  noun.append(c)

words = [wor for c in noun for wor in c]

v_n = [n for n,c in Counter(words).most_common(500)]

!pip install sklearn
from sklearn.feature_extraction.text import TfidfVectorizer
df = pd.DataFrame({"text":comment})
df['text'] = df['text'].apply(lambda x: ' '.join([word for word in x]))
vectorizer = TfidfVectorizer(vocabulary=v_n, ngram_range=(1,2))
TF_IDF = vectorizer.fit_transform(df['text'].values)
TF_IDF_array = TF_IDF.toarray()

import numpy as np
sum = np.sum(TF_IDF_array,axis=0).tolist()

rank = pd.DataFrame({"feature":vectorizer.get_feature_names(),"index": sum}).sort_values("index", ascending=False)
rank.head(20)

aspects = rank.head(20)["feature"]

aspects

"""**Aspect Categorization**"""

!pip install gensim
import gensim

from gensim.models import Word2Vec

www = [word for item in sent_c for word in item]

len(Counter(www).keys())

def skip(sent, n=3, s=2):
  k_grams = []
  for i in range(len(sent)):
    for z in range(s):
      seq = [sent[i]] + sent[i+z+1:i+z+n]
      if len(seq) == n and seq not in k_grams:
        k_grams.append(list(seq))
  return k_grams

sent_c1 = [sent for sent in sent_c if sent != []]

sequences = []
for i in sent_c1:
  l = skip(i)
  sequences.append(l)

sequences = [sent for sent in sequences if sent != []]
seq = [s for sent in sequences for s in sent]

seq[:10]

model = Word2Vec(seq, min_count=50)

word = 'staff'
model.wv.most_similar(positive=word)

aspect_c = defaultdict(list)
for i in aspects:
  similar = model.wv.most_similar(positive=i)
  for w, s in similar:
    aspect_c[i].append(w)

aspect_c.keys()

d = ['facility', 'air', 'petrol', 'service', 'pump']
for i in d:
  aspect_c.pop(i)
category = dict(aspect_c)

for (a, s) in category.items():
  for wor in s:
    w,t = nltk.pos_tag([wor])[0]
    if t[0] != 'N':
      category[a].remove(wor)

category

category ={'accept': ['payment',
  'upi',
  'payment accept',
  'card',
  'cash',
  'card accept'],
 'all facility': ['facility available',
  'facility',
  'toilet',
  'include',
  'washroom',
  'water',
  'drinking water',
  'clean',
  'drink'],
 'card': ['part',
  'cash',
  'debit card',
  'credit card',
  'accept',
  'upi',
  'payment',
  'accepts',
  'wallet'],
 'diesel': ['all time',
  'pure',
  'petrol diesel',
  'petrol',
  'sell',
  'accurate',
  'gas',
  'premium'],
 'fill': ['tank', 'put', 'person', 'wait', 'bike', 'air fill', 'try to', 'u'],
 'fuel': ['product',
  'petroleum',
  'pure',
  'supply',
  'accurate',
  'sell',
  'measurement',
  'suggest',
  'issue'],
 'oil': ['corporation',
  'engine',
  'petroleum',
  'outlet',
  'city',
  'use',
  'change',
  'indian oil',
  'reward'],
 'payment': ['accept',
  'payment accept',
  'upi',
  'part',
  'accepts',
  'mode',
  'cash',
  'card accept',
  'wallet'],
 'place': ['visit', 'this place', 'location', 'near', 'main', 'area'],
 'quality': ['quantity',
  'and quantity',
  'good quality',
  'accurate',
  'pure',
  'petrol',
  'product',
  'fuel',
  'diesel'],
 'staff': ['staff be',
  'all staff',
  'behave',
  'area',
  'behaviour',
  'customer',
  'location'],
 'station': ['pump',
  'road',
  'place',
  'good',
  'this place',
  'petrol',
  'location'],
 'time': ['go', 'queue', 'location', 'all time', 'crowd', 'lot', 'visit'],
 'type': ['method',
  'digital payment',
  'payment mode',
  'online payment',
  'payment option',
  'mobile',
  'option',
  'transaction',
  'card payment'],
 'work': ['machine',
  'person',
  'guy',
  'puncture',
  'tyre',
  'air fill',
  'put',
  'fill']}

for k in category.keys():
  category[k].append(k)

c_v = [wor for k,v in category.items() for wor in v]

cc = []
for com in com_sent:
  ccc = []
  for sent in com:
    ss = []
    for wor in sent:
      if wor not in c_v:
        ss.append(wor)
      else:
        for k in category.keys():
          if wor in category[k]:
            ss.append(k)
    ccc.append(ss)
  cc.append(ccc)

opinion_d = []
for com in cc:
  com_d = defaultdict(list)
  for s in com:
    for k in category.keys():
      if any(w in s for w in category[k]) is True:
        com_d[k].append(s)
  opinion_d.append(dict(com_d))

opinion_d

opinion = pd.DataFrame({"opinion sentences": opinion_d, "recommendation": data["Review"] , "editor selection": data["new_reviews"]})

opinion.drop(opinion[opinion['opinion sentences'] == {}].index, inplace = True)

opinion

"""**Sentiment Orientation**"""

def split_sentence(o_p, k):
  if k in o_p.keys():
    list_s = o_p[k]
  else:
    list_s = []
  return list_s

for k in category.keys():
  m = []
  for i in opinion['opinion sentences']:
    x = split_sentence(i, k)
    m.append(x)
  opinion[k] = m

# staff
staff = pd.DataFrame({"staff": opinion['staff']})
staff = staff[staff['staff'].apply(lambda x: len(x)) > 0]
staff_index = list(staff.index)

def word_list(l):
  ll = []
  for i in list(l):
    w = []
    for s in i:
      for word in s:
        w.append(word)
    ll.append(w)
  return ll

def get_v(list_p):
  v = [w for s in list_p for w in s]
  feature = [k for k, v in Counter(v).most_common() if v > 5]
  return feature

staff_list = word_list(staff["staff"])
feature1 = get_v(staff_list)
staff_list = pd.DataFrame({"staff":staff_list})
staff_list['staff'] = staff_list['staff'].apply(lambda x: ' '.join([word for word in x]))

vectorizer = TfidfVectorizer(vocabulary=feature1, ngram_range=(1,2))
TF_IDF1 = vectorizer.fit_transform(staff_list['staff'].values)
TF_IDF_array1 = TF_IDF1.toarray()

from sklearn.cluster import KMeans
kmeans1 = KMeans(n_clusters=2, random_state=0).fit(TF_IDF1)

from sklearn.metrics import pairwise_distances_argmin_min
closest1, _ = pairwise_distances_argmin_min(kmeans1.cluster_centers_, TF_IDF1)

sentences[staff_index[closest1[0]]]  # positive

sentences[staff_index[closest1[1]]]  # negative

label1 = kmeans1.labels_

opinion["senti1"] = np.zeros(len(opinion))
for i in range(len(label1)):
  if label1[i] == 0:
    opinion["senti1"][staff_index[i]] = -1
  if label1[i] == 1:
    opinion["senti1"][staff_index[i]] = 1

# work
work = pd.DataFrame({"work": opinion['work']})
work = work[work['work'].apply(lambda x: len(x)) > 0]
work_index = list(work.index)

work_list = word_list(work["work"])
feature2 = get_v(work_list)
work_list = pd.DataFrame({"work":work_list})
work_list['work'] = work_list['work'].apply(lambda x: ' '.join([word for word in x]))

vectorizer2 = TfidfVectorizer(vocabulary=feature2, ngram_range=(1,2))
TF_IDF2 = vectorizer2.fit_transform(work_list['work'].values)
kmeans2 = KMeans(n_clusters=2, random_state=0).fit(TF_IDF2)
closest2, _ = pairwise_distances_argmin_min(kmeans2.cluster_centers_, TF_IDF2)

sentences[work_index[closest2[0]]] # positive

sentences[work_index[closest2[1]]] # negative

label2 = kmeans2.labels_
opinion["senti2"] = np.zeros(len(opinion))
for i in range(len(label2)):
  if label2[i] == 0:
    opinion["senti2"][work_index[i]] = -1
  if label2[i] == 1:
    opinion["senti2"][work_index[i]] = 1

# station
station = pd.DataFrame({"station": opinion['station']})
station = station[station['station'].apply(lambda x: len(x)) > 0]
station_index = list(station.index)

station_list = word_list(station["station"])
feature3 = get_v(station_list)
station_list = pd.DataFrame({"station":station_list})
station_list['station'] = station_list['station'].apply(lambda x: ' '.join([word for word in x]))

vectorizer3 = TfidfVectorizer(vocabulary=feature3, ngram_range=(1,2))
TF_IDF3 = vectorizer3.fit_transform(station_list['station'].values)
kmeans3 = KMeans(n_clusters=2, random_state=0).fit(TF_IDF3)
closest3, _ = pairwise_distances_argmin_min(kmeans3.cluster_centers_, TF_IDF3)

sentences[station_index[closest3[0]]] # negative

sentences[station_index[closest3[1]]] # positive

label3 = kmeans3.labels_
opinion["senti3"] = np.zeros(len(opinion))
for i in range(len(label3)):
  if label3[i] == 0:
    opinion["senti3"][station_index[i]] = -1
  if label3[i] == 1:
    opinion["senti3"][station_index[i]] = 1



































































































































"""**Text Classification**"""

!pip install imbalanced-learn
import imblearn
from imblearn.over_sampling import ADASYN
from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline
import matplotlib.pyplot as plt
from sklearn.metrics import plot_confusion_matrix

from sklearn.model_selection import train_test_split, cross_val_score, KFold, cross_validate
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, f1_score, accuracy_score

y = opinion['editor selection']
X = opinion.iloc[:, 17:31]

opinion['editor selection'].value_counts()

opinion.shape

import seaborn as sns
sns.set(style="white")
graph = sns.countplot(x = opinion['editor selection'], data = opinion,palette="hls")
i = 0
for p in graph.patches:
  height = p.get_height()
  graph.text(p.get_x()+p.get_width()/2., height + 0.1,
         '{0:.0%}'.format((opinion['editor selection'].value_counts()[i])/26717),ha="center")
  i += 1
plt.figure
plt.savefig('fig5.eps', bbox_inches='tight')

graph2 = sns.countplot(x="variable", hue="value", data=pd.melt(X))
graph2.set_xticklabels(graph2.get_xticklabels(), rotation=40, ha="right")
plt.xlabel('Aspects')
plt.figure
plt.savefig('fig6.eps', bbox_inches='tight')

oversample = ADASYN()
X, y = oversample.fit_resample(X, y)

Counter(y)

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.4,random_state=11,stratify=y)

cv = KFold(n_splits=10, random_state=1, shuffle=True)

forest1 = RandomForestClassifier(oob_score = True, n_jobs = -1)

clf1 = LogisticRegression(random_state=0)

scores1 = cross_val_score(forest1, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)

scores2 = cross_val_score(clf1, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)

from numpy import mean, std

print('Performce of Random Forest: %.3f' % (mean(scores1)))

print('Performance of Logistic Regraression: %.3f' % (mean(scores2)))

y_test_pred1 = forest1.fit(X_train,y_train).predict(X_test)
y_test_pred2 = clf1.fit(X_train,y_train).predict(X_test)

print("Accuracy of test - Random Forest:",metrics.accuracy_score(y_test, y_test_pred1))
print("Accuracy of test - Logistic Regression:",metrics.accuracy_score(y_test, y_test_pred2))

target_names = ["0","1"]
print(classification_report(y_test, y_test_pred1, target_names=target_names))

print(classification_report(y_test, y_test_pred2, target_names=target_names))

import matplotlib.pyplot as plt
from sklearn.metrics import plot_confusion_matrix
cm1 = plot_confusion_matrix(forest1, X_test, y_test, display_labels = ['0','1'], cmap=plt.cm.Blues, values_format = "d")
plt.title("Model a",fontweight="bold")
cm1.ax_.get_images()[0].set_clim(1500, 9000)
plt.figure
plt.savefig('fig1.eps', bbox_inches='tight')

cm2 = plot_confusion_matrix(clf1, X_test, y_test, display_labels = ['0','1'], cmap=plt.cm.Blues, values_format = "d")
plt.title("Model b",fontweight="bold")
cm2.ax_.get_images()[0].set_clim(1500, 9000)
plt.figure
plt.savefig('fig2.eps', bbox_inches='tight')

forest_roc_auc = roc_auc_score(y_test, forest1.predict(X_test))
fpr, tpr, thresholds = roc_curve(y_test, forest1.predict_proba(X_test)[:,1])
plt.figure()
plt.plot(fpr, tpr, label='Random Forest (area = %0.2f)' % forest_roc_auc)
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title("Model a",fontweight="bold")
plt.legend(loc="lower right")
plt.figure
plt.savefig('fig7.eps', bbox_inches='tight')

logit_roc_auc = roc_auc_score(y_test, clf1.predict(X_test))
fpr, tpr, thresholds = roc_curve(y_test, clf1.predict_proba(X_test)[:,1])
plt.figure()
plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title("Model b",fontweight="bold")
plt.legend(loc="lower right")
plt.figure
plt.savefig('fig8.eps', bbox_inches='tight')

X_c = np.zeros([51999, 28])

# dummy
for j in range(51999):
  for i in range(14):
    ii = 2*i
    if X[j,i] == 1:
      X_c[j,ii] = 1
    if X[j,i] == -1:
      X_c[j,ii+1] = 1

X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X_c,y,test_size=0.4,random_state=11,stratify=y)

forest2 = RandomForestClassifier(oob_score = True, n_jobs = -1)

clf2 = LogisticRegression(random_state=0)

scores3 = cross_val_score(forest2, X_train_c, y_train_c, scoring='accuracy', cv=cv, n_jobs=-1)

scores4 = cross_val_score(clf2, X_train_c, y_train_c, scoring='accuracy', cv=cv, n_jobs=-1)

print('Performce of Random Forest: %.3f' % (mean(scores3)))

print('Performance of Logistic Regraression: %.3f' % (mean(scores4)))

y_test_pred3 = forest2.fit(X_train_c,y_train_c).predict(X_test_c)
y_test_pred4 = clf2.fit(X_train_c,y_train_c).predict(X_test_c)

print("Accuracy of test - Random Forest:",metrics.accuracy_score(y_test_c, y_test_pred3))
print("Accuracy of test - Logistic Regression:",metrics.accuracy_score(y_test_c, y_test_pred4))

print(classification_report(y_test_c, y_test_pred3, target_names=target_names))

print(classification_report(y_test_c, y_test_pred4, target_names=target_names))

forest_roc_auc = roc_auc_score(y_test_c, forest2.predict(X_test_c))
fpr, tpr, thresholds = roc_curve(y_test_c, forest2.predict_proba(X_test_c)[:,1])
plt.figure()
plt.plot(fpr, tpr, label='Random Forest (area = %0.2f)' % forest_roc_auc)
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title("Model c",fontweight="bold")
plt.legend(loc="lower right")
plt.figure
plt.savefig('fig9.eps', bbox_inches='tight')
files.download("fig9.eps")

lr_roc_auc = roc_auc_score(y_test_c, clf2.predict(X_test_c))
fpr, tpr, thresholds = roc_curve(y_test_c, clf2.predict_proba(X_test_c)[:,1])
plt.figure()
plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend(loc="lower right")
plt.title("Model d",fontweight="bold")
plt.legend(loc="lower right")
plt.figure
plt.savefig('fig10.eps', bbox_inches='tight')
files.download("fig10.eps")

cm3 = plot_confusion_matrix(forest2, X_test_c, y_test_c, display_labels = ['0','1'], cmap=plt.cm.Blues, values_format = "d")
cm3.ax_.get_images()[0].set_clim(1500, 9000)
plt.title("Model c",fontweight="bold")
plt.figure
plt.savefig('fig3.eps', bbox_inches='tight')
files.download("fig3.eps")

cm4 = plot_confusion_matrix(clf2, X_test_c, y_test_c, display_labels = ['0','1'], cmap=plt.cm.Blues, values_format = "d")
cm4.ax_.get_images()[0].set_clim(1500, 9000)
plt.title("Model d",fontweight="bold")
plt.figure
plt.savefig('fig4.eps', bbox_inches='tight')
files.download("fig4.eps")